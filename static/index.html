<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width" />
    <title>Conversation API</title>
  </head>

  <body>
    <style>
      body {
        background: #000;
      }
    </style>

    <!-- <button id="start-recording">Start recording</button> -->

    <script>
      // IMPORTANT: the audio recorded by the MediaRecorder is what considered "conteinerized" aduio,
      // so when this data is passed to deepgram it should NOT specify encoding, sample_rate and channels
      // https://developers.deepgram.com/docs/determining-your-audio-format-for-live-streaming-audio/#streaming-containerized-audio

      const TIMESLICE = 500;

      const OUTPUT_FORMAT = "mp3_44100";
      const WS_URL = "ws://localhost:4000";

      async function conversation() {
        const ws = new WebSocket(`${WS_URL}?output_format=${OUTPUT_FORMAT}`);

        ws.addEventListener("error", (e) => console.error("[üçå] error", e));
        ws.addEventListener("close", (e) => console.log("[üçå] closed", e));
        ws.addEventListener("open", (e) => console.log("[üçå] opened", e));

        const audioContext = new AudioContext();

        let nextStartTime = audioContext.currentTime;
        const queue = [];

        async function schedulePlayback() {
          while (queue.length > 0) {
            const blob = queue.shift();

            const arrayBuffer = await blob.arrayBuffer();

            const source = audioContext.createBufferSource();
            source.buffer = await audioContext.decodeAudioData(arrayBuffer);
            source.connect(audioContext.destination);

            const startTime = Math.max(nextStartTime, audioContext.currentTime);
            nextStartTime = startTime + source.buffer.duration;

            source.start(startTime);

            source.onended = () => {
              source.disconnect();
            };
          }
        }

        ws.addEventListener("message", async (event) => {
          console.log("[üßΩ] audio chunk recieved...", event.data);

          queue.push(event.data);

          schedulePlayback();
        });

        const stream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });

        const recorder = new MediaRecorder(stream);

        recorder.ondataavailable = async (event) => {
          if (event.data.size === 0 || ws.readyState !== WebSocket.OPEN) {
            return;
          }

          console.log(
            "[üìΩÔ∏è] sending recorded audio chunk...",
            event.data.size,
            event.data.type
          );

          ws.send(event.data);
        };

        recorder.start(TIMESLICE);
      }

      conversation();
    </script>
  </body>
</html>
